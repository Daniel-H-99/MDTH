dataset_params:
  root_dir: /mnt/hdd/minyeong_workspace/data/Voxceleb
  cache: /mnt/hdd/minyeong_workspace/data/Voxceleb
  landmarkmodel_path: /mnt/hdd/minyeong_workspace/checkpoints/landmark
  frame_shape: [256, 256, 3]
  id_sampling: True
  pairs_list: None
  augmentation_params:
    flip_param:
      horizontal_flip: True
      time_flip: True
    jitter_param:
      brightness: 0.1
      contrast: 0.1
      saturation: 0.1
      hue: 0.1


model_params:
  common_params:
    num_kp: 15
    # sections:  [[[17, 18, 19, 20, 21], 2], [[36, 37, 38, 39, 40, 41], 2], [[22, 23, 24, 25, 26], 2], [[42, 43, 44, 45, 46, 47], 2], [[48, 49, 50, 51, 52, 53, 54 ,55, 56, 57, 58, 59], 4], [[60, 61, 62, 63, 64, 65, 66, 67], 2], [[0, 1, 2, 14, 15, 16, 27, 28, 29, 30], 6], [[3], 1], [[4], 1]]
    image_channel: 3                    
    feature_channel: 32
    estimate_jacobian: False   # True
  kp_detector_params:
     temperature: 0.1
     block_expansion: 32            
     max_features: 1024
     scale_factor: 0.25         # 0.25
     num_blocks: 5
     reshape_channel: 16384  # 16384 = 1024 * 16
     reshape_depth: 16
  he_estimator_params:
     block_expansion: 64            
     max_features: 2048
     num_bins: 66
  exp_transformer_params:
    block_expansion: 64            
    max_features: 2048
    num_bins: 66
    num_layer: 1
    num_heads: 128
    input_dim: 2048
  generator_params:
    block_expansion: 64
    max_features: 512
    num_down_blocks: 2
    reshape_channel: 32
    reshape_depth: 16         # 512 = 32 * 16
    num_resblocks: 6
    estimate_occlusion_map: True
    dense_motion_params:
      block_expansion: 32
      max_features: 1024
      num_blocks: 5
      # reshape_channel: 32
      reshape_depth: 16
      compress: 4
  discriminator_params:
    scales: [1]
    block_expansion: 32                 
    max_features: 512
    num_blocks: 4
    sn: True

train_params:
  num_epochs: 600
  num_repeats: 1
  epoch_milestones: [180,]
  lr_generator: 2.0e-4
  lr_discriminator: 2.0e-4
  lr_kp_detector: 2.0e-4
  lr_he_estimator: 2.0e-4
  lr_exp_transformer: 2.0e-4
  gan_mode: 'hinge'    # hinge or ls
  batch_size: 12
  scales: [1, 0.5, 0.25, 0.125]
  checkpoint_freq: 10
  hopenet_snapshot: 'hopenet_robust_alpha1.pkl'
  transform_params:
    sigma_affine: 0.05
    sigma_tps: 0.005
    points_tps: 5
  id_classifier_scale: 0.625 # 160 / image size
  loss_weights:
    generator_gan: 1                  
    discriminator_gan: 1
    feature_matching: [10, 10, 10, 10]
    perceptual: [10, 10, 10, 10, 10]
    equivariance_value: 0
    equivariance_jacobian: 0    # 10
    keypoint: 0
    headpose: 0
    motion_match: 0
    log: 0
    expression: 0
    localized: [0, 0, 0, 0, 0, 0, 0, 0, 0]
    style: 0
    id_cls: 10
    l1: 10

visualizer_params:
  kp_size: 5
  draw_border: True
  colormap: 'gist_rainbow'
